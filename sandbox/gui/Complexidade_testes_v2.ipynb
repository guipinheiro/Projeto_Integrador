{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexidade dos Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> **Próximos Passos:** </span>\n",
    "\n",
    "Sistemas Envolvidos - Montar nivel de Complexidade\n",
    "- Tempo Execução\n",
    "- Quantidade de Steps\n",
    "- Combinação com o Sistema Principal\n",
    "- Um Cenrário, todos os Casos de testes são feitos no mesmo sistema?\n",
    "- Poderá ter vies do funcionario ter mais habilidade e por isso o tempo de execução ser menor?\n",
    "- Faturável ou não faturável: Pode ter maior concentração de rejeição em algum sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import re\n",
    "\n",
    "sns.set()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import das bases de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_fat = pd.read_csv(\"data/Exec_Faturaveis.csv\", \n",
    "                       parse_dates=['Data_Execucao', 'Data_FechamentoCenario', 'Hora_Execucao', 'Fechamento_CT'])\n",
    "exec_nfat = pd.read_csv(\"data/Exec_NaoFaturaveis.csv\",\n",
    "                       parse_dates=['Data_Execucao', 'Data_FechamentoCenario', 'Hora_Execucao','Fechamento_CT'])\n",
    "exec_fcst = pd.read_csv(\"data/Exec_Forecast.csv\",\n",
    "                       parse_dates=['Data_Execucao', 'Data_FechamentoCenario', 'Hora_Execucao', 'Fechamento_CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_full = pd.concat([exec_fat, exec_nfat, exec_fcst], ignore_index=True)\n",
    "exec_full.tail()\n",
    "exec_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_full.columns\n",
    "exec_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filtra somente testes com tempo de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra somente testes com tempo de execução\n",
    "exec_full_valid = exec_full[exec_full[\"Duracao_Segundos\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_full_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_full_valid.Nome_CT.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extraindo somente o verbo da Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir os espaços \" - \" por \"-\"\n",
    "exec_full_valid['Nome_CT'] = exec_full_valid['Nome_CT'].apply([lambda x: re.sub(r'\\s+', ' ', x)])\n",
    "exec_full_valid['Nome_CT'] = exec_full_valid['Nome_CT'].apply([lambda x: x.replace(r' - ', '-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair somente o verbo o caso de teste\n",
    "def verbo_CT (texto):\n",
    "    a = texto.split(\" \", 1)[0]\n",
    "    a.split(' ', 1)\n",
    "    word1 = \" \".join(re.findall(\"[a-zA-Z]+\", a))\n",
    "    #verbo = word1.split(\" \", 1)[1]\n",
    "    return word1\n",
    "\n",
    "def replace_CT (texto):\n",
    "    verbo = texto.split(\" \", 10)[1]\n",
    "    return verbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando na mão casos bizarros\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Nome_CT'].apply(lambda x : verbo_CT(x))\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('CT', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C T ATLYS ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C T API ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C T NGIN ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('T ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('TC ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('CN ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C BDFIN ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C PUTTY ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C BDA ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('ATLYS ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C Putty ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C Atlys', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('C ', '')])\n",
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace('PUTTY', '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_full_valid['Verbo_test'] = exec_full_valid['Verbo_test'].apply([lambda x: x.replace(r' ', '')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DataSet dos Sisitemas + Verbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist = exec_full_valid.groupby(['Sistemas_Envolvidos','Sistema_Principal','Verbo_test']).agg({'Testador_Real': {\"qtde_total_teste\": 'count'},\n",
    "                                                                                   'Duracao_Segundos': {\"tempo_medio\": 'mean', \"tempo_min\": 'min', \"tempo_max\": 'max', \"tempo_total\": 'sum', \"tempo_std\": 'std'},\n",
    "                                                                                   'Qtde_TotalSteps': {\"qtde_steps_medio\": 'mean',\"qtde_steps_min\": 'min',\"qtde_steps_max\": 'max',\"qtde_steps_sum\": 'sum', \"qtde_steps_std\": 'std'},\n",
    "                                                                                   'Qtde_StepsATTACHMENT': {\"qtde_steps_att_medio\": 'mean',\"qtde_steps_att_min\": 'min',\"qtde_steps_att_max\": 'max',\"qtde_steps_att_sum\": 'sum',\"qtde_steps_att_std\": 'std'},\n",
    "                                                                                   'Qtde_ExecPassed': {\"qtde_steps_pass_medio\": 'mean',\"qtde_step_pass_min\": 'min',\"qtde_steps_pass_max\": 'max',\"qtde_steps_pass_sum\": 'sum', \"qtde_steps_pass_std\": 'std'}})\n",
    "                                                                                  \n",
    "                                                                        \n",
    "complex_sist.columns = complex_sist.columns.droplevel(0)\n",
    "complex_sist = complex_sist.reset_index()\n",
    "complex_sist.head(2)                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. DataSet do tempo gasto de acordo com o VERBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbo = exec_full_valid.groupby(['Verbo_test']).agg({'Duracao_Segundos': {\"tempo_medio\": 'mean', \"tempo_min\": 'min', \"tempo_max\": 'max'},\n",
    "                                                     'Qtde_TotalSteps': {\"qtde_steps_medio\": 'mean',\"qtde_steps_min\": 'min',\"qtde_steps_max\": 'max'}})\n",
    "                                                                                  \n",
    "                                                                        \n",
    "verbo.columns = verbo.columns.droplevel(0)\n",
    "verbo = verbo.reset_index()\n",
    "verbo.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbo.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combinando os dois DataSets e Extraindo as Dumies da combinação dos sistemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist = complex_sist.merge(verbo, left_on='Verbo_test', right_on='Verbo_test',suffixes=('', '_verbo'))\n",
    "complex_sist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sist_dummies = complex_sist.Sistema_Principal.str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sist_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(complex_sist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex_sist_fim = pd.concat([sist_dummies, complex_sist], join=\"inner\")\n",
    "complex_sist_fim = complex_sist.merge(sist_dummies, left_on=sist_dummies.index, right_on=complex_sist.index)\n",
    "complex_sist_fim.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist_fim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(complex_sist_fim.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropei estas columas por conterem missing \n",
    "complex_sist_fim = complex_sist_fim.drop(['key_0', \"tempo_std\", \"qtde_steps_std\", \"qtde_steps_pass_std\",'qtde_steps_att_std'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cluster da Complexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica presença de missing\n",
    "import missingno as msno\n",
    "msno.matrix(complex_sist_fim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist_fim['tempo_medio_step'] = complex_sist_fim['tempo_total']/complex_sist_fim['qtde_steps_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sist_fim.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropei estas columas que se relacionam com tempo por step\n",
    "columas_logit = complex_sist_fim.drop([\"tempo_total\", \"qtde_steps_sum\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columas_logit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.1'> 8. Clustering Complexidade dos Testes por Sistema </a>\n",
    "Voltar: <a href='#0'>Sumário  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columas_logit.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columas_logit = complex_sist_fim.drop([\"tempo_total\", \"qtde_steps_sum\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = complex_sist.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(figsize=(15, 12));\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        ax=ax,\n",
    "        annot=True,\n",
    "        mask=mask,\n",
    "        square=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def run_regression(df,function):\n",
    "    model = smf.ols(function, df).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_regression(columas_logit,'''tempo_medio_step ~  qtde_total_teste + tempo_min + tempo_max''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(complex_sist.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_clustering = complex_sist.drop([   \n",
    "\"Sistema_Principal\",\n",
    "\"Sistemas_Envolvidos\",\n",
    "\"Verbo_test\",   \n",
    "\"qtde_steps_att_sum\",\n",
    "\"qtde_steps_att_max\",\n",
    "\"tempo_medio_verbo\",\n",
    "\"tempo_min_verbo\",\n",
    "\"qtde_steps_min\",\n",
    "\"qtde_steps_max\",\n",
    "\"tempo_min\",\n",
    "\"qtde_steps_pass_medio\",\n",
    "\"qtde_steps_pass_max\",\n",
    "\"tempo_std\", \n",
    "\"qtde_steps_std\", \n",
    "\"qtde_steps_pass_std\",\n",
    "'qtde_steps_att_std'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica presença de missing\n",
    "import missingno as msno\n",
    "msno.matrix(colunas_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_clustering.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "def metodo_elbow(max_nro_clusters, X):\n",
    "    wcss = [] \n",
    "    for i in range(1, max_nro_clusters):\n",
    "        kmeans = KMeans(n_clusters = i, init = 'random')\n",
    "        kmeans.fit(X)\n",
    "        #print (i,kmeans.inertia_)\n",
    "        wcss.append(kmeans.inertia_)  \n",
    "    plt.plot(range(1, max_nro_clusters), wcss)\n",
    "    plt.title('O Metodo Elbow')\n",
    "    plt.xlabel('Numero de Clusters')\n",
    "    plt.ylabel('WSS') #within cluster sum of squares\n",
    "simulacao = metodo_elbow(15, colunas_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# random categorical data\n",
    "data = complex_sist_fim\n",
    "\n",
    "km = KModes(n_clusters=6, init='Huang', n_init=5, verbose=1)\n",
    "\n",
    "clusters = km.fit_predict(data)\n",
    "\n",
    "# Print the cluster centroids\n",
    "print(km.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroides = km.cluster_centroids_\n",
    "centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(centroides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#--------------------------------------------------------------------------------------#\n",
    "# 1) Roda o DBSCAN\n",
    "#--------------------------------------------------------------------------------------#\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pipeline_DBSCAN (base):\n",
    "    \n",
    "    # Standarize features\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(base)\n",
    "    \n",
    "    #     \n",
    "    dbsc = DBSCAN(eps = .1, min_samples = 10).fit(X)\n",
    "    labels = dbsc.labels_\n",
    "    core_samples = np.zeros_like(labels, dtype = bool)\n",
    "    core_samples[dbsc.core_sample_indices_] = True\n",
    "\n",
    "    cluster_found_db = pd.Series(labels, name='cluster')\n",
    "    df0_ = df0.set_index(cluster_found_db, append=True )\n",
    "    df0_.head()\n",
    "\n",
    "    print(f'Clusters DBScan: {cluster_found_db.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
